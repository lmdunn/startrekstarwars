{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4690a53c-c990-43d7-b5d4-7bdb57e29ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "from datetime import date\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2017aa3-502c-4674-92ee-df8a2ef6e19f",
   "metadata": {},
   "source": [
    "I developed the function below in a separate notebook. Please let me know if you'd like to see it. A note on it: it appears that there are posts that don't actually translate to rows in the dataframe. In other words, they wind up counting toward the 'limit' (in this case 100), but don't actually save into the dataframe. After talking to Alanna about it, it seemed clear the problem was with the data and not the function and that it wasn't worth the time it would take to dig down and figure out which posts that was and why, but rather to work with the data that I got. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ab85d5b4-2ef3-408b-8925-0d6c66cf8b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_reddit_df(subreddit, desired_size, endpoint = '/reddit/search/submission', limit = 100):\n",
    "    \n",
    "    '''\n",
    "    NOTE: you must set your desired dataframe equal to this function to save the dataframe outside the function.\n",
    "    \n",
    "    This function is designed to use pushshift API to build a dataframe of specified size \n",
    "    filled with data from the specified subreddit. It starts with the most recent post and works backwards.\n",
    "\n",
    "    subreddit = the subreddit you'd like to scrape\n",
    "    \n",
    "    desired_size = the total number of posts you'd like to have in the dataframe. The function will hit the minimum size \n",
    "        above that value that the 'limit' value allows. In other words, it may go over this value up to the amount of the limit.\n",
    "    \n",
    "    endpoint = your desired endpoint. Defaults to '/reddit/search/submission' for submissions (main post) and\n",
    "       '/reddit/search/comment' for comments at the time of the writing of this function (6/22/2022)     \n",
    "\n",
    "    limit = the limit for number of posts that can be pulled at once. The default is 100, the maximum\n",
    "        allowed at the time of the writing of this function (6/22/2022)\n",
    "    '''\n",
    "    \n",
    "    url = 'https://api.pushshift.io'+endpoint\n",
    "    \n",
    "    counter = 0\n",
    "    \n",
    "    fncdf = pd.DataFrame() #establish with certainty that the new dataframe name is empty.\n",
    "    \n",
    "    for i in range(2):\n",
    "   \n",
    "        if len(fncdf) == 0:\n",
    "            params = {\n",
    "                'subreddit': subreddit,\n",
    "                'size': limit,\n",
    "                'filter': ['title', 'selftext', 'subreddit', 'created_utc'] #katie pointed out this parameter to me to save cleaning later.\n",
    "            }\n",
    "            res = requests.get(url, params)\n",
    "            if res.status_code == 200:\n",
    "                data = res.json()\n",
    "                posts = data['data']\n",
    "                fncdf = pd.DataFrame(posts)\n",
    "                counter += 1\n",
    "            else:\n",
    "                print(f'ERROR: status code not 200. Failure occured on loop number {counter+1}')\n",
    "\n",
    "        else: # after the df has been established.\n",
    "            while len(fncdf) < desired_size:\n",
    "                params = {\n",
    "                    'subreddit': subreddit,\n",
    "                    'size': limit,\n",
    "                    'before': fncdf.iloc[-1]['created_utc'],\n",
    "                    'filter': ['title', 'selftext', 'subreddit', 'created_utc']\n",
    "                }\n",
    "                res = requests.get(url, params)\n",
    "\n",
    "                if res.status_code == 200:\n",
    "                    data = res.json()\n",
    "                    posts = data['data']\n",
    "                    newdf = pd.DataFrame(posts)\n",
    "                    fncdf = pd.concat([fncdf, newdf], ignore_index = True)\n",
    "                    counter +=1\n",
    "                    time.sleep(3) #alanna suggested adding this\n",
    "\n",
    "                else:\n",
    "                    print('ERROR: status code not 200. Failure occured on loop number {counter+1}')\n",
    "    \n",
    "    return fncdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "acb4fbc6-ee43-4613-8f59-ecacea1b8678",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "startrek = build_reddit_df('startrek', 3500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06cb006-2662-4b8f-9db8-268013d172d0",
   "metadata": {},
   "source": [
    "I'm backing this dataset up because otherwise I can't go back and explore the separate sets of posts without cleaning again because of the time-related nature of what's puled into the initial dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "3551315d-2517-476f-9495-4882a816ade7",
   "metadata": {},
   "outputs": [],
   "source": [
    "startrekbackup = startrek.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "515c6945-13b0-4ee3-b46e-65dd4c923e32",
   "metadata": {},
   "source": [
    "I used [this stackoverflow answer](https://stackoverflow.com/a/50885228) to guide my work on eliminating duplicates. My rationale is that any duplicate submissions will only overfit the model. This site showed me [a way to use .drop_duplicates](https://stackoverflow.com/a/58311003) that preserves specific values that are duplicated. See why, below.\n",
    "\n",
    "While my initial instinct was to delete \"[removed]\" and blank posts, I was curious to see that the 'starwars' subreddit seems to have far more [removed] posts. I found [this post](https://www.reddit.com/r/NoStupidQuestions/comments/b3czg1/what_does_removed_mean/) that indicated that \"[removed]\" means that a moderator has taken down the post. It appears that the level of '[removed]' may help indicate if a post is a Star Wars or Star Trek post simply because a higher percentage of them are removed. While I ultimately intend to use 'removed' as a stop word and/or remove those lines from the dataframe, I'm opting to leave those posts in for now so I can explore them further. I'd also like to be able to leave the data of the residual titles in the dataframe for now and intend to examine those, too.\n",
    "\n",
    "I considered carefully whether or not to remove duplicate titles. The argument for keeping is that at least on the StarWars subreddit, [reposting is explicitly forbidden](https://www.reddit.com/r/StarWars/wiki/rules#wiki_read_and_follow_reddiquette), so there's potentially a relationship between repetition and removal. However, as I'm interested in exploring the languaged used in the title's of removed posts and particularly word-counts, I'd rather lose the potential to explore patterns of repetition in favor of not overweighting the words appearing in the titles. On the day that I drew my data, there were 53 repeated Star Trek titles and 83 repeated Star Wars titles. These represent a relatively small number of data points.\n",
    "\n",
    "I also became curious to see if the blank 'selftext' rows reflected what appeared to be posts that consisted more-or-less solely of the title. That appears to be the case, so I'm going to keep those in the dataframe, as well. In addition to being able to use the titles, I'll be curious to see if there are discrepancies in how many posts of that type the two subredditors create.\n",
    "\n",
    "I'm going to pull 3500 of both Star Trek and Star Wars posts to ensure that I have at least 1000 of each that have text in their 'selftext', in case I decide to remove the blank and '[removed]' posts in analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "d70b7b07-066c-4324-8dc1-1e6d30efebf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(startrek[startrek.duplicated(['title'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "65ae124a-eeab-4776-85dd-e1419351c7cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Shape: (3595, 4)\n",
      "====================\n",
      "Initial Top 5 Value Counts: [removed]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1408\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       647\n",
      "This movie just didn't do it for me.  No wonder it killed the Kelvin timeline.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           4\n",
      "https://imgur.com/a/M4OrgDc                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              2\n",
      "I really loved every storyline within the episode. I loved how they humanized both Una and La'an, that interrogation scene was hilarious. I loved the diplomatic negotiations too, I love how they bring in the new aliens with the different characteristics and explore their perspectives in every episode. SNW truly feels like the modernized TOS. \\n\\nEvery character becomes more and more lovable and likeable!\\n\\nMy favorite parts, however, intrigue me and confuse me a bit at the same time. \\n\\nFirst things first, our girl Chapel is officially a bisexual hoe (good for her)! What I loved the most was Chapel and Spock's dynamic and chemistry. The way Christine validated Spock's Vulkanness and Humanity was so endearing and Spock getting irritated at and punching that dude who insulted Chapel was fun to watch as well. So, there is definitely a special friendship and understanding being formed between the two. \\n\\nAnd yet, I wouldn't say they are a case of relationship I would be satisfied to see remain purely platonic, because it isn't from Chapel's perspective, she definitely has a crush on Spock already and we know she is going to have this yearning for him throughout, like, the decades. \\n\\nChapel looks at Spock kind of longingly throughout the episode and don't get me wrong, I love sad romance, but I wonder how it is going to work out considering how the things ended between Spock and T'pring (who is also an interesting character) in the episode? Though, I think it becomes clear why Spock and T'pring broke up eventually, neither could give the other what they truly needed.\\n\\nI want Strange New Worlds to flesh out Chapel's attraction and attachment to Spock and their friendship and also, explore Chapel's backstory which is hinted to be traumatic I think.       2\n",
      "Name: selftext, dtype: int64\n",
      "\n",
      "====================\n",
      "\n",
      "Final Shape: (3537, 4)\n",
      "====================\n",
      "Final Top 5 Value Counts: [removed]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     1394\n",
      "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               630\n",
      "[deleted]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        2\n",
      "I grew up in the 2000s watching VHS tapes my Dad made in the 90s of TOS and TNG. What a great intro to sci-fi! As an adult the closest I’ve come to liking Nu-Trek is watching the 2007 reboot and Beyond. Tried watching Discovery and Picard, but they fail to capture what makes Star Trek special. Hope, optimism, bright colours, the spirit of exploration … people coming together to solve timeless problems that each of us have our own window into - that’s what nu-Trek has been missing. I think we had a glimpse of it the 2007 movie and Beyond, but this is the first pilot that makes me believe 21st century Star Trek can be something other than a bleak imagination of our future. I can’t wait to see more, this pilot at least proves that it’s possible to make new Star Trek that brings back those warm feelings I oh so missed!       1\n",
      "I guess three days in the past is enough to make some captains abandon their ship and crew in the future. It's like if Kirk, in \"The City on the Edge of Forever,\" decided nah, he was just going to stick around with Edith Keeler.                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             1\n",
      "Name: selftext, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Initial Shape: {startrek.shape}')\n",
    "print('='*20)\n",
    "print(f'Initial Top 5 Value Counts: {startrek[\"selftext\"].value_counts().head()}')\n",
    "startrek = pd.concat([startrek[startrek['selftext']=='[removed]'],\n",
    "                     startrek[startrek['selftext']==''],\n",
    "                     startrek[startrek['selftext']=='[deleted]'],\n",
    "                     startrek[(startrek['selftext'] != '[removed]') & (startrek['selftext'] != '') & (startrek['selftext'] != '[deleted]')]\\\n",
    "                      .drop_duplicates([\"selftext\"], keep = 'first')])\n",
    "startrek = startrek.drop_duplicates(['title'], keep = 'first')\n",
    "print('')\n",
    "print('='*20)\n",
    "print('')\n",
    "print(f'Final Shape: {startrek.shape}')\n",
    "print('='*20)\n",
    "print(f'Final Top 5 Value Counts: {startrek[\"selftext\"].value_counts().head()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2ba99f85-4d4b-4279-8e82-7eb14994df38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(startrek[startrek.duplicated(['title'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb42bb7-290b-4f18-a56f-65836d61182a",
   "metadata": {},
   "source": [
    "The below is to confirm that the 'selftext' isn't repeated other than '[removed]', '[deleted]', '['']', and nulls, which I'll deal with later. Just checking for duplicates is not enough because of the repetition of those four things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c9a401ee-d407-4ead-8fd8-32aaad9db739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1656254308</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>startrek</td>\n",
       "      <td>On the Gorn and language</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1656248567</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>startrek</td>\n",
       "      <td>What are some good things that can be said abo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1656238740</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>startrek</td>\n",
       "      <td>A Lord of the Rings reference in SNW 1x08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1656238132</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>startrek</td>\n",
       "      <td>The sword props used in SNW 1x08 are replicas ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1656237020</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>startrek</td>\n",
       "      <td>TNG vs the world?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3582</th>\n",
       "      <td>1650549682</td>\n",
       "      <td></td>\n",
       "      <td>startrek</td>\n",
       "      <td>The Ready Room: \"Mercy\" (Jeri Ryan and Santiag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3583</th>\n",
       "      <td>1650546302</td>\n",
       "      <td></td>\n",
       "      <td>startrek</td>\n",
       "      <td>What the hell is Rios doing in Star Trek Picar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3585</th>\n",
       "      <td>1650538210</td>\n",
       "      <td></td>\n",
       "      <td>startrek</td>\n",
       "      <td>Star Trek: Picard Is Garbage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3593</th>\n",
       "      <td>1650508756</td>\n",
       "      <td></td>\n",
       "      <td>startrek</td>\n",
       "      <td>The Realism of Science Fiction in Old Trek vs ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>1651490479</td>\n",
       "      <td>[deleted]</td>\n",
       "      <td>startrek</td>\n",
       "      <td>I have to say, Marvel did a better job... [Spo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2023 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      created_utc   selftext subreddit  \\\n",
       "5      1656254308  [removed]  startrek   \n",
       "8      1656248567  [removed]  startrek   \n",
       "11     1656238740  [removed]  startrek   \n",
       "12     1656238132  [removed]  startrek   \n",
       "13     1656237020  [removed]  startrek   \n",
       "...           ...        ...       ...   \n",
       "3582   1650549682             startrek   \n",
       "3583   1650546302             startrek   \n",
       "3585   1650538210             startrek   \n",
       "3593   1650508756             startrek   \n",
       "2946   1651490479  [deleted]  startrek   \n",
       "\n",
       "                                                  title  \n",
       "5                              On the Gorn and language  \n",
       "8     What are some good things that can be said abo...  \n",
       "11            A Lord of the Rings reference in SNW 1x08  \n",
       "12    The sword props used in SNW 1x08 are replicas ...  \n",
       "13                                    TNG vs the world?  \n",
       "...                                                 ...  \n",
       "3582  The Ready Room: \"Mercy\" (Jeri Ryan and Santiag...  \n",
       "3583  What the hell is Rios doing in Star Trek Picar...  \n",
       "3585                       Star Trek: Picard Is Garbage  \n",
       "3593  The Realism of Science Fiction in Old Trek vs ...  \n",
       "2946  I have to say, Marvel did a better job... [Spo...  \n",
       "\n",
       "[2023 rows x 4 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "startrek[(startrek.duplicated(['selftext']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "7a09c206-14aa-41a2-a5cd-5ce12dc4a62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stonlytext = startrek[(startrek['selftext'] != '[removed]') & (startrek['selftext'].notnull()) & (startrek['selftext'] != '') & (startrek['selftext'] != '[deleted]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b0481499-360f-4fb8-8d44-a013dd2b6de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [created_utc, selftext, subreddit, title]\n",
       "Index: []"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stonlytext[stonlytext.duplicated(['selftext'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "828e0bd6-cfb5-4bb6-b7dc-cdb777b23665",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1656264455</td>\n",
       "      <td></td>\n",
       "      <td>StarWars</td>\n",
       "      <td>One of the most heartwarming moments I’ve ever...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1656264338</td>\n",
       "      <td>Lego Star Wars: The Video Game is a Lego game ...</td>\n",
       "      <td>StarWars</td>\n",
       "      <td>Lego Star Wars: The Video Game was released be...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1656264179</td>\n",
       "      <td>Writing was horrible constant nostalgia pander...</td>\n",
       "      <td>StarWars</td>\n",
       "      <td>My rant on obiwan show</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1656263912</td>\n",
       "      <td>My friends love to piss me off and say its lik...</td>\n",
       "      <td>StarWars</td>\n",
       "      <td>Is it AT-AT(aht-aht) or is it A T-A T (a t- a t)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1656263896</td>\n",
       "      <td>Maul. We know he’s around mixing it up with in...</td>\n",
       "      <td>StarWars</td>\n",
       "      <td>Obi-wan Kenobi Season 2 - Must have Cameo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   created_utc                                           selftext subreddit  \\\n",
       "0   1656264455                                                     StarWars   \n",
       "1   1656264338  Lego Star Wars: The Video Game is a Lego game ...  StarWars   \n",
       "2   1656264179  Writing was horrible constant nostalgia pander...  StarWars   \n",
       "3   1656263912  My friends love to piss me off and say its lik...  StarWars   \n",
       "4   1656263896  Maul. We know he’s around mixing it up with in...  StarWars   \n",
       "\n",
       "                                               title  \n",
       "0  One of the most heartwarming moments I’ve ever...  \n",
       "1  Lego Star Wars: The Video Game was released be...  \n",
       "2                             My rant on obiwan show  \n",
       "3   Is it AT-AT(aht-aht) or is it A T-A T (a t- a t)  \n",
       "4          Obi-wan Kenobi Season 2 - Must have Cameo  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starwars = build_reddit_df('starwars', 3500)\n",
    "starwars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da2e5dd-269b-47e6-87cc-fc497ee6dc4c",
   "metadata": {},
   "source": [
    "I'm backing this dataset up because otherwise I can't go back and explore the separate sets of posts without cleaning again because of the time-related nature of what's puled into the initial dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "f53258da-45fc-4c22-b7dd-069b5d10690e",
   "metadata": {},
   "outputs": [],
   "source": [
    "starwarsbackup = starwars.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c32db0aa-158a-452d-8a04-176260175ab6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(starwars[starwars.duplicated(['title'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "67f0d778-7df1-4e9c-99d5-962f78c65c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Shape: (3500, 4)\n",
      "====================\n",
      "Initial Top 5 Value Counts:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  1777\n",
      "[removed]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                         560\n",
      "[deleted]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           3\n",
      "In my opinion, Her acting wasn't hitting at all. I get that her character is supposed to be over the top, but her execution sucks. Cringe and awkward at times. Basically a girl version of Michale B Jordan..                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      2\n",
      "I would like to let people know that this will contain major spoilers. Yes, I am fully aware of the series is decades old, but I always like to leave a warning as a courtesy.  With that out of the way, let's continue with the main topic.\\n\\nAs we all know, when Luke and Obi-Wan Kenobi first meet, they are discussing topics regarding the Jedi and the Dark times that fell upon the Republic.  When Luke asked how his father died, Obi-Wan Kenobi mentioned that a former pupil of his named Darth Vader betrayed and murdered his father.\\n\\nThe question I have to ask is did George Lucas intend for Darth Vader to not have any family relation with Luke?  When we were first told of the event with Luke's father, it was a rather direct explanation of one person murdering another.  Later on, we found out that Obi-Wan was telling his story from a certain point of view.  Darth Vader was not a person.  He was the physical manifestation of the evil that took over and extinguished the light side that was Anakin Skywalker.\\n\\nWas this always going to be the storyline since the initial production around the late '70s?  If so, I'm wondering if there are any interviews that can confirm it.  Otherwise, I think Lucas personally had thought of the idea of Darth Vader not having any relation with a main character, but Irvin Kershner felt it was a bigger impact to change that idea for the sequel.       2\n",
      "Name: selftext, dtype: int64\n",
      "\n",
      "====================\n",
      "\n",
      "Final Shape: (3409, 4)\n",
      "====================\n",
      "Final Top 5 Value Counts:                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            1728\n",
      "[removed]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   542\n",
      "[deleted]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     3\n",
      "I’m constantly intrigued by this lore. Wouldn’t this suggest that the crystals powering their sabers are also sentient beings? Correct me if I’m ignorant.                                                                                                                                                                                                                                                                                                                                                                                                                                                                    1\n",
      "Dear r/StarWars,\\nOver the last several years the history of Star Wars has been… tumultuous to say the least. Fans were divided after Disney’s handling of the franchise, but I think we can all agree on one thing - R2D2: Beneath the Dome is a fabulous mockumentary with the most amazing actors ranging from Christopher Lee to Carrie Fisher, all in on this joke that R2D2 is an actor and chronicles his journey from birth in a small London town to present day of 2001. With Disney’s resurgence of the franchise, I think it’s time we get a part 2 and see how Reginald is doing. Can this happen, please?       1\n",
      "Name: selftext, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'Initial Shape: {starwars.shape}')\n",
    "print('='*20)\n",
    "print(f'Initial Top 5 Value Counts: {starwars[\"selftext\"].value_counts().head()}')\n",
    "starwars = pd.concat([starwars[starwars['selftext']=='[removed]'],\n",
    "                     starwars[starwars['selftext']==''],\n",
    "                     starwars[starwars['selftext']=='[deleted]'],\n",
    "                     starwars[(starwars['selftext'] != '[removed]') & (starwars['selftext'] != '') & (starwars['selftext'] != '[deleted]')]\\\n",
    "                      .drop_duplicates([\"selftext\"], keep = 'first')])\n",
    "starwars = starwars.drop_duplicates(['title'])\n",
    "print('')\n",
    "print('='*20)\n",
    "print('')\n",
    "print(f'Final Shape: {starwars.shape}')\n",
    "print('='*20)\n",
    "print(f'Final Top 5 Value Counts: {starwars[\"selftext\"].value_counts().head()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6d55820e-98ce-474c-9715-ca9ab0b46ae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(starwars[starwars.duplicated(['title'])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61abe574-f70b-49a0-affe-1bc3dc830c11",
   "metadata": {},
   "source": [
    "Checking to make sure the duplicate 'selftext' has been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "ff0c0602-2d26-4bd0-8131-a9d3e1f77532",
   "metadata": {},
   "outputs": [],
   "source": [
    "swonlytext = starwars[(starwars['selftext'] != '[removed]') & (starwars['selftext'].notnull()) & (starwars['selftext'] != '') & (starwars['selftext'] != '[deleted]')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "d2476259-ee77-44cf-84e0-292f5049b7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_utc</th>\n",
       "      <th>selftext</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [created_utc, selftext, subreddit, title]\n",
       "Index: []"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swonlytext[swonlytext.duplicated(['selftext'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "ab444513-ba7b-42d2-a41a-1502d1082db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Star Trek Shape: (3537, 4)\n",
      "Star Wars Shape: (3409, 4)\n",
      "Combined Shape: (6946, 4)\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([startrek, starwars])\n",
    "print(f'Star Trek Shape: {startrek.shape}')\n",
    "print(f'Star Wars Shape: {starwars.shape}')\n",
    "print(f'Combined Shape: {df.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "40eecf13-cc33-42e1-be84-5325d88b6b26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6946"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "3537+3409"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ace40879-a013-46d5-890f-1c2414f6d50a",
   "metadata": {},
   "source": [
    "Because the function always pullest the newest posts to the given subreddits, I've written the following to write the data to a csv marked with the date and to prevent the file from being overwritten if this cell is run more than once in a day. This seems particularly important to preserving the actual data that was used for my analysis.\n",
    "\n",
    "[This site](https://www.geeksforgeeks.org/python-datetime-module/) showed me how to call the date. I remembered we checked if a directory existed with `os` during the Excel Lab (2.01), but I needed [this site](https://www.pythontutorial.net/python-basics/python-check-if-file-exists/) to understand what to call to check if the file existed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "15e232ce-9915-471a-8eaf-6add6473aeb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "created_utc     int64\n",
       "selftext       object\n",
       "subreddit      object\n",
       "title          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "bd80e69d-cf56-4175-8811-5e9e5fce3e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(f'data/data{date.today()}.csv') == True:\n",
    "    print('ERROR: This filename exists. Please choose a different filename. FILE WAS NOT SAVED.')\n",
    "else:\n",
    "    df.to_csv(f'data/data{date.today()}.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "3ce8d0ae-412f-48a1-ac49-033e8597c598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# below is a line that can be uncommented and used to create a new dataframe on the same date.\n",
    "# It's set to create data{TODAY'SDATE}-1.\n",
    "\n",
    "# df.to_csv(f'data/data{date.today()}-1.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f09c94ab-387b-4abb-b0ac-991f28ffb1cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsi]",
   "language": "python",
   "name": "conda-env-dsi-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
